# PIPELINE DEFINITION
# Name: credit-risk-pipeline
# Description: End-to-end MLOps pipeline for credit risk scoring model
# Inputs:
#    auc_threshold: float [Default: 0.75]
#    dataset_url: str [Default: 'https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls']
#    learning_rate: float [Default: 0.03]
#    max_depth: int [Default: 4.0]
#    model_name: str [Default: 'credit-risk-model']
#    n_estimators: int [Default: 500.0]
#    stage: str [Default: 'staging']
#    test_size: float [Default: 0.2]
# Outputs:
#    data-loader-metrics: system.Metrics
#    feature-engineer-metrics: system.Metrics
#    register-model-metrics: system.Metrics
#    train-model-metrics: system.Metrics
#    validate-model-metrics: system.Metrics
components:
  comp-data-loader:
    executorLabel: exec-data-loader
    inputDefinitions:
      parameters:
        dataset_url:
          parameterType: STRING
        test_size:
          parameterType: NUMBER_DOUBLE
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        test_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-feature-engineer:
    executorLabel: exec-feature-engineer
    inputDefinitions:
      artifacts:
        test_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_data:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        scaler_artifact:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        test_features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
  comp-register-model:
    executorLabel: exec-register-model
    inputDefinitions:
      artifacts:
        model_artifact:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        scaler_artifact:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        validation_report:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        model_name:
          parameterType: STRING
        stage:
          parameterType: STRING
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        registered_model:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
  comp-train-model:
    executorLabel: exec-train-model
    inputDefinitions:
      artifacts:
        test_features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
        train_features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        learning_rate:
          parameterType: NUMBER_DOUBLE
        max_depth:
          parameterType: NUMBER_INTEGER
        n_estimators:
          parameterType: NUMBER_INTEGER
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        model_artifact:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
  comp-validate-model:
    executorLabel: exec-validate-model
    inputDefinitions:
      artifacts:
        model_artifact:
          artifactType:
            schemaTitle: system.Model
            schemaVersion: 0.0.1
        test_features:
          artifactType:
            schemaTitle: system.Dataset
            schemaVersion: 0.0.1
      parameters:
        auc_threshold:
          parameterType: NUMBER_DOUBLE
    outputDefinitions:
      artifacts:
        metrics:
          artifactType:
            schemaTitle: system.Metrics
            schemaVersion: 0.0.1
        validation_report:
          artifactType:
            schemaTitle: system.Artifact
            schemaVersion: 0.0.1
      parameters:
        Output:
          parameterType: BOOLEAN
deploymentSpec:
  executors:
    exec-data-loader:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - data_loader
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.3'\
          \ 'scikit-learn==1.3.2' && \"$0\" \"$@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef data_loader(\n    dataset_url: str,\n    test_size: float,\n\
          \    train_data: Output[Dataset],\n    test_data: Output[Dataset],\n   \
          \ metrics: Output[Metrics]\n):\n    \"\"\"Load credit card dataset and split\
          \ into train/test sets.\"\"\"\n    import pandas as pd\n    from sklearn.model_selection\
          \ import train_test_split\n\n    # Load dataset\n    print(f\"Loading dataset\
          \ from {dataset_url}...\")\n    df = pd.read_csv(dataset_url)\n\n    # Rename\
          \ columns\n    column_names = {\n        'X1': 'LIMIT_BAL', 'X2': 'SEX',\
          \ 'X3': 'EDUCATION', 'X4': 'MARRIAGE', 'X5': 'AGE',\n        'X6': 'PAY_0',\
          \ 'X7': 'PAY_2', 'X8': 'PAY_3', 'X9': 'PAY_4', 'X10': 'PAY_5', 'X11': 'PAY_6',\n\
          \        'X12': 'BILL_AMT1', 'X13': 'BILL_AMT2', 'X14': 'BILL_AMT3', 'X15':\
          \ 'BILL_AMT4', \n        'X16': 'BILL_AMT5', 'X17': 'BILL_AMT6',\n     \
          \   'X18': 'PAY_AMT1', 'X19': 'PAY_AMT2', 'X20': 'PAY_AMT3', 'X21': 'PAY_AMT4',\
          \ \n        'X22': 'PAY_AMT5', 'X23': 'PAY_AMT6',\n        'Y': 'DEFAULT'\n\
          \    }\n    df = df.rename(columns=column_names)\n\n    # Split data\n \
          \   train_df, test_df = train_test_split(\n        df, test_size=test_size,\
          \ random_state=42, stratify=df['DEFAULT']\n    )\n\n    # Save outputs\n\
          \    train_df.to_csv(train_data.path, index=False)\n    test_df.to_csv(test_data.path,\
          \ index=False)\n\n    # Log metrics\n    metrics.log_metric(\"total_samples\"\
          , len(df))\n    metrics.log_metric(\"train_samples\", len(train_df))\n \
          \   metrics.log_metric(\"test_samples\", len(test_df))\n    metrics.log_metric(\"\
          default_rate\", float(df['DEFAULT'].mean()))\n\n    print(f\"\u2705 Data\
          \ loaded: {len(train_df)} train, {len(test_df)} test samples\")\n\n"
        image: python:3.10-slim
    exec-feature-engineer:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - feature_engineer
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.3'\
          \ 'scikit-learn==1.3.2' 'numpy==1.24.3' 'joblib==1.3.2' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef feature_engineer(\n    train_data: Input[Dataset],\n    test_data:\
          \ Input[Dataset],\n    train_features: Output[Dataset],\n    test_features:\
          \ Output[Dataset],\n    scaler_artifact: Output[Model],\n    metrics: Output[Metrics]\n\
          ):\n    \"\"\"Apply feature engineering transformations to the dataset.\"\
          \"\"\n    import pandas as pd\n    import numpy as np\n    from sklearn.preprocessing\
          \ import StandardScaler\n    import joblib\n\n    # Load data\n    train_df\
          \ = pd.read_csv(train_data.path)\n    test_df = pd.read_csv(test_data.path)\n\
          \n    def engineer_features(df):\n        \"\"\"Apply feature engineering\
          \ transformations.\"\"\"\n        pay_cols = ['PAY_0', 'PAY_2', 'PAY_3',\
          \ 'PAY_4', 'PAY_5', 'PAY_6']\n        bill_cols = ['BILL_AMT1', 'BILL_AMT2',\
          \ 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\n        amt_cols\
          \ = ['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n\
          \n        # Payment behavior features\n        df['LATE_PAYMENTS'] = (df[pay_cols]\
          \ > 0).sum(axis=1)\n        df['MAX_DELAY'] = df[pay_cols].max(axis=1)\n\
          \        df['AVG_DELAY'] = df[pay_cols].mean(axis=1)\n        df['SEVERE_DELAY']\
          \ = (df[pay_cols] >= 2).sum(axis=1)\n        df['EVER_2MONTH_LATE'] = (df[pay_cols]\
          \ >= 2).any(axis=1).astype(int)\n        df['RECENT_DELAY_WEIGHTED'] = df['PAY_0']\
          \ * 3 + df['PAY_2'] * 2 + df['PAY_3']\n\n        # Aggregates\n        df['AVG_BILL_AMT']\
          \ = df[bill_cols].mean(axis=1)\n        df['AVG_PAY_AMT'] = df[amt_cols].mean(axis=1)\n\
          \        df['TOTAL_BILL'] = df[bill_cols].sum(axis=1)\n        df['TOTAL_PAY']\
          \ = df[amt_cols].sum(axis=1)\n\n        # Ratios\n        df['UTILIZATION']\
          \ = df['BILL_AMT1'] / (df['LIMIT_BAL'] + 1)\n        df['AVG_UTILIZATION']\
          \ = df['AVG_BILL_AMT'] / (df['LIMIT_BAL'] + 1)\n        df['PAY_RATIO']\
          \ = df['TOTAL_PAY'] / (df['TOTAL_BILL'] + 1)\n        df['RECENT_PAY_RATIO']\
          \ = df['PAY_AMT1'] / (df['BILL_AMT1'] + 1)\n\n        # Trends\n       \
          \ df['BILL_TREND'] = df['BILL_AMT1'] - df['BILL_AMT6']\n        df['PAY_TREND']\
          \ = df['PAY_AMT1'] - df['PAY_AMT6']\n        df['INCREASING_DEBT'] = (df['BILL_TREND']\
          \ > 0).astype(int)\n\n        # Interactions\n        df['LIMIT_AGE'] =\
          \ df['LIMIT_BAL'] / df['AGE']\n        df['DELAY_UTIL'] = df['AVG_DELAY']\
          \ * df['AVG_UTILIZATION']\n\n        # Categorical\n        df['HIGH_EDUCATION']\
          \ = (df['EDUCATION'] <= 2).astype(int)\n        df['SINGLE'] = (df['MARRIAGE']\
          \ == 2).astype(int)\n\n        # Handle infinity\n        df = df.replace([np.inf,\
          \ -np.inf], np.nan)\n        df = df.fillna(0)\n\n        return df\n\n\
          \    # Apply feature engineering\n    train_df = engineer_features(train_df)\n\
          \    test_df = engineer_features(test_df)\n\n    # Separate features and\
          \ target\n    feature_cols = [col for col in train_df.columns if col !=\
          \ 'DEFAULT']\n\n    X_train = train_df[feature_cols]\n    y_train = train_df['DEFAULT']\n\
          \    X_test = test_df[feature_cols]\n    y_test = test_df['DEFAULT']\n\n\
          \    # Scale features\n    scaler = StandardScaler()\n    X_train_scaled\
          \ = scaler.fit_transform(X_train)\n    X_test_scaled = scaler.transform(X_test)\n\
          \n    # Create output DataFrames\n    train_out = pd.DataFrame(X_train_scaled,\
          \ columns=feature_cols)\n    train_out['DEFAULT'] = y_train.values\n\n \
          \   test_out = pd.DataFrame(X_test_scaled, columns=feature_cols)\n    test_out['DEFAULT']\
          \ = y_test.values\n\n    # Save outputs\n    train_out.to_csv(train_features.path,\
          \ index=False)\n    test_out.to_csv(test_features.path, index=False)\n \
          \   joblib.dump(scaler, scaler_artifact.path)\n\n    # Log metrics\n   \
          \ metrics.log_metric(\"num_features\", len(feature_cols))\n    metrics.log_metric(\"\
          engineered_features\", 22)\n\n    print(f\"\u2705 Feature engineering complete:\
          \ {len(feature_cols)} features\")\n\n"
        image: python:3.10-slim
    exec-register-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - register_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'mlflow==2.9.2'\
          \ 'xgboost==2.0.3' 'pandas==2.0.3' 'scikit-learn==1.3.2' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef register_model(\n    model_artifact: Input[Model],\n    scaler_artifact:\
          \ Input[Model],\n    validation_report: Input[Artifact],\n    model_name:\
          \ str,\n    stage: str,\n    registered_model: Output[Artifact],\n    metrics:\
          \ Output[Metrics]\n):\n    \"\"\"Register validated model in MLflow registry.\"\
          \"\"\n    import mlflow\n    import mlflow.xgboost\n    import xgboost as\
          \ xgb\n    import joblib\n    import json\n    import os\n\n    # Set MLflow\
          \ tracking URI (use environment variable or default)\n    mlflow_uri = os.getenv(\"\
          MLFLOW_TRACKING_URI\", \"sqlite:///mlflow.db\")\n    mlflow.set_tracking_uri(mlflow_uri)\n\
          \n    # Load validation report\n    with open(validation_report.path, 'r')\
          \ as f:\n        validation_result = json.load(f)\n\n    if not validation_result.get(\"\
          passed\", False):\n        print(\"\u274C Model validation failed - skipping\
          \ registration\")\n        metrics.log_metric(\"registered\", 0)\n     \
          \   return\n\n    # Load model\n    model = xgb.XGBClassifier()\n    model.load_model(model_artifact.path)\n\
          \n    # Set experiment\n    mlflow.set_experiment(\"credit-risk-pipeline\"\
          )\n\n    with mlflow.start_run(run_name=f\"pipeline-{model_name}\"):\n \
          \       # Log model\n        mlflow.xgboost.log_model(\n            model,\n\
          \            artifact_path=\"model\",\n            registered_model_name=model_name\n\
          \        )\n\n        # Log validation metrics\n        mlflow.log_metric(\"\
          auc\", validation_result[\"auc\"])\n        mlflow.log_metric(\"validation_passed\"\
          , int(validation_result[\"passed\"]))\n\n        # Log scaler\n        mlflow.log_artifact(scaler_artifact.path,\
          \ artifact_path=\"preprocessing\")\n\n        # Log validation report\n\
          \        mlflow.log_artifact(validation_report.path, artifact_path=\"validation\"\
          )\n\n        run_id = mlflow.active_run().info.run_id\n\n    # Create registration\
          \ info\n    registration_info = {\n        \"model_name\": model_name,\n\
          \        \"run_id\": run_id,\n        \"stage\": stage,\n        \"auc\"\
          : validation_result[\"auc\"],\n        \"mlflow_uri\": mlflow_uri\n    }\n\
          \n    with open(registered_model.path, 'w') as f:\n        json.dump(registration_info,\
          \ f, indent=2)\n\n    # Log metrics\n    metrics.log_metric(\"registered\"\
          , 1)\n    metrics.log_metric(\"auc\", float(validation_result[\"auc\"]))\n\
          \n    print(f\"\u2705 Model registered: {model_name} (run_id: {run_id})\"\
          )\n    print(f\"   Stage: {stage}\")\n    print(f\"   AUC: {validation_result['auc']:.4f}\"\
          )\n\n"
        image: python:3.10-slim
    exec-train-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - train_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.3'\
          \ 'scikit-learn==1.3.2' 'xgboost==2.0.3' 'joblib==1.3.2' && \"$0\" \"$@\"\
          \n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef train_model(\n    train_features: Input[Dataset],\n    test_features:\
          \ Input[Dataset],\n    max_depth: int,\n    learning_rate: float,\n    n_estimators:\
          \ int,\n    model_artifact: Output[Model],\n    metrics: Output[Metrics]\n\
          ):\n    \"\"\"Train XGBoost model on the engineered features.\"\"\"\n  \
          \  import pandas as pd\n    import xgboost as xgb\n    from sklearn.metrics\
          \ import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n\
          \    import joblib\n\n    # Load data\n    train_df = pd.read_csv(train_features.path)\n\
          \    test_df = pd.read_csv(test_features.path)\n\n    X_train = train_df.drop('DEFAULT',\
          \ axis=1)\n    y_train = train_df['DEFAULT']\n    X_test = test_df.drop('DEFAULT',\
          \ axis=1)\n    y_test = test_df['DEFAULT']\n\n    # Calculate class weight\n\
          \    scale_pos_weight = len(y_train[y_train==0]) / len(y_train[y_train==1])\n\
          \n    # Train model\n    print(f\"Training XGBoost: depth={max_depth}, lr={learning_rate},\
          \ n_est={n_estimators}\")\n\n    model = xgb.XGBClassifier(\n        objective='binary:logistic',\n\
          \        max_depth=max_depth,\n        learning_rate=learning_rate,\n  \
          \      n_estimators=n_estimators,\n        subsample=0.8,\n        colsample_bytree=0.8,\n\
          \        min_child_weight=5,\n        gamma=0.2,\n        reg_alpha=0.5,\n\
          \        reg_lambda=2.0,\n        scale_pos_weight=scale_pos_weight,\n \
          \       random_state=42,\n    )\n\n    model.fit(\n        X_train, y_train,\n\
          \        eval_set=[(X_test, y_test)],\n        verbose=False\n    )\n\n\
          \    # Predictions\n    y_pred = model.predict(X_test)\n    y_pred_proba\
          \ = model.predict_proba(X_test)[:, 1]\n\n    # Calculate metrics\n    auc\
          \ = roc_auc_score(y_test, y_pred_proba)\n    accuracy = accuracy_score(y_test,\
          \ y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall =\
          \ recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n\n  \
          \  # Log metrics\n    metrics.log_metric(\"auc\", float(auc))\n    metrics.log_metric(\"\
          accuracy\", float(accuracy))\n    metrics.log_metric(\"precision\", float(precision))\n\
          \    metrics.log_metric(\"recall\", float(recall))\n    metrics.log_metric(\"\
          f1\", float(f1))\n\n    # Save model\n    model.save_model(model_artifact.path)\n\
          \n    print(f\"\u2705 Model trained: AUC={auc:.4f}, Accuracy={accuracy:.4f}\"\
          )\n\n"
        image: python:3.10-slim
    exec-validate-model:
      container:
        args:
        - --executor_input
        - '{{$}}'
        - --function_to_execute
        - validate_model
        command:
        - sh
        - -c
        - "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip ||\
          \ python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1\
          \ python3 -m pip install --quiet --no-warn-script-location 'kfp==2.7.0'\
          \ '--no-deps' 'typing-extensions>=3.7.4,<5; python_version<\"3.9\"'  &&\
          \  python3 -m pip install --quiet --no-warn-script-location 'pandas==2.0.3'\
          \ 'scikit-learn==1.3.2' 'xgboost==2.0.3' 'matplotlib==3.7.3' && \"$0\" \"\
          $@\"\n"
        - sh
        - -ec
        - 'program_path=$(mktemp -d)


          printf "%s" "$0" > "$program_path/ephemeral_component.py"

          _KFP_RUNTIME=true python3 -m kfp.dsl.executor_main                         --component_module_path                         "$program_path/ephemeral_component.py"                         "$@"

          '
        - "\nimport kfp\nfrom kfp import dsl\nfrom kfp.dsl import *\nfrom typing import\
          \ *\n\ndef validate_model(\n    model_artifact: Input[Model],\n    test_features:\
          \ Input[Dataset],\n    auc_threshold: float,\n    validation_report: Output[Artifact],\n\
          \    metrics: Output[Metrics]\n) -> bool:\n    \"\"\"Validate model meets\
          \ AUC threshold and generate validation report.\"\"\"\n    import pandas\
          \ as pd\n    import xgboost as xgb\n    from sklearn.metrics import roc_auc_score,\
          \ classification_report, confusion_matrix, roc_curve\n    import matplotlib.pyplot\
          \ as plt\n    import json\n\n    # Load model and data\n    model = xgb.XGBClassifier()\n\
          \    model.load_model(model_artifact.path)\n\n    test_df = pd.read_csv(test_features.path)\n\
          \    X_test = test_df.drop('DEFAULT', axis=1)\n    y_test = test_df['DEFAULT']\n\
          \n    # Predictions\n    y_pred = model.predict(X_test)\n    y_pred_proba\
          \ = model.predict_proba(X_test)[:, 1]\n\n    # Calculate AUC\n    auc =\
          \ roc_auc_score(y_test, y_pred_proba)\n    passed = auc >= auc_threshold\n\
          \n    # Generate classification report\n    report = classification_report(y_test,\
          \ y_pred, output_dict=True)\n    cm = confusion_matrix(y_test, y_pred).tolist()\n\
          \n    # Create validation report\n    validation_result = {\n        \"\
          auc\": float(auc),\n        \"auc_threshold\": float(auc_threshold),\n \
          \       \"passed\": passed,\n        \"classification_report\": report,\n\
          \        \"confusion_matrix\": cm,\n        \"feature_count\": len(X_test.columns),\n\
          \        \"test_samples\": len(y_test)\n    }\n\n    # Save report\n   \
          \ with open(validation_report.path, 'w') as f:\n        json.dump(validation_result,\
          \ f, indent=2)\n\n    # Log metrics\n    metrics.log_metric(\"auc\", float(auc))\n\
          \    metrics.log_metric(\"auc_threshold\", float(auc_threshold))\n    metrics.log_metric(\"\
          validation_passed\", int(passed))\n    metrics.log_metric(\"precision_default\"\
          , float(report['1']['precision']))\n    metrics.log_metric(\"recall_default\"\
          , float(report['1']['recall']))\n\n    # Generate ROC curve plot\n    fpr,\
          \ tpr, _ = roc_curve(y_test, y_pred_proba)\n    plt.figure(figsize=(8, 6))\n\
          \    plt.plot(fpr, tpr, 'b-', linewidth=2, label=f'Model (AUC = {auc:.4f})')\n\
          \    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n    plt.axhline(y=auc_threshold,\
          \ color='r', linestyle='--', label=f'Threshold = {auc_threshold}')\n   \
          \ plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n\
          \    plt.title(f'ROC Curve - Validation {\"PASSED\" if passed else \"FAILED\"\
          }')\n    plt.legend()\n    plt.grid(True, alpha=0.3)\n    plt.savefig(validation_report.path.replace('.json',\
          \ '_roc.png'), dpi=100)\n\n    status = \"\u2705 PASSED\" if passed else\
          \ \"\u274C FAILED\"\n    print(f\"{status}: AUC={auc:.4f} (threshold: {auc_threshold})\"\
          )\n\n    return passed\n\n"
        image: python:3.10-slim
pipelineInfo:
  description: End-to-end MLOps pipeline for credit risk scoring model
  name: credit-risk-pipeline
root:
  dag:
    outputs:
      artifacts:
        data-loader-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: data-loader
        feature-engineer-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: feature-engineer
        register-model-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: register-model
        train-model-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: train-model
        validate-model-metrics:
          artifactSelectors:
          - outputArtifactKey: metrics
            producerSubtask: validate-model
    tasks:
      data-loader:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-data-loader
        inputs:
          parameters:
            dataset_url:
              componentInputParameter: dataset_url
            test_size:
              componentInputParameter: test_size
        taskInfo:
          name: 1. Load Data
      feature-engineer:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-feature-engineer
        dependentTasks:
        - data-loader
        inputs:
          artifacts:
            test_data:
              taskOutputArtifact:
                outputArtifactKey: test_data
                producerTask: data-loader
            train_data:
              taskOutputArtifact:
                outputArtifactKey: train_data
                producerTask: data-loader
        taskInfo:
          name: 2. Feature Engineering
      register-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-register-model
        dependentTasks:
        - feature-engineer
        - train-model
        - validate-model
        inputs:
          artifacts:
            model_artifact:
              taskOutputArtifact:
                outputArtifactKey: model_artifact
                producerTask: train-model
            scaler_artifact:
              taskOutputArtifact:
                outputArtifactKey: scaler_artifact
                producerTask: feature-engineer
            validation_report:
              taskOutputArtifact:
                outputArtifactKey: validation_report
                producerTask: validate-model
          parameters:
            model_name:
              componentInputParameter: model_name
            stage:
              componentInputParameter: stage
        taskInfo:
          name: 5. Register Model
      train-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-model
        dependentTasks:
        - feature-engineer
        inputs:
          artifacts:
            test_features:
              taskOutputArtifact:
                outputArtifactKey: test_features
                producerTask: feature-engineer
            train_features:
              taskOutputArtifact:
                outputArtifactKey: train_features
                producerTask: feature-engineer
          parameters:
            learning_rate:
              componentInputParameter: learning_rate
            max_depth:
              componentInputParameter: max_depth
            n_estimators:
              componentInputParameter: n_estimators
        taskInfo:
          name: 3. Train XGBoost
      validate-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-validate-model
        dependentTasks:
        - feature-engineer
        - train-model
        inputs:
          artifacts:
            model_artifact:
              taskOutputArtifact:
                outputArtifactKey: model_artifact
                producerTask: train-model
            test_features:
              taskOutputArtifact:
                outputArtifactKey: test_features
                producerTask: feature-engineer
          parameters:
            auc_threshold:
              componentInputParameter: auc_threshold
        taskInfo:
          name: 4. Validate Model
  inputDefinitions:
    parameters:
      auc_threshold:
        defaultValue: 0.75
        description: Minimum AUC required for model validation
        isOptional: true
        parameterType: NUMBER_DOUBLE
      dataset_url:
        defaultValue: https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls
        description: URL or path to the credit card dataset
        isOptional: true
        parameterType: STRING
      learning_rate:
        defaultValue: 0.03
        description: XGBoost learning rate
        isOptional: true
        parameterType: NUMBER_DOUBLE
      max_depth:
        defaultValue: 4.0
        description: XGBoost max tree depth
        isOptional: true
        parameterType: NUMBER_INTEGER
      model_name:
        defaultValue: credit-risk-model
        description: Name for model registration
        isOptional: true
        parameterType: STRING
      n_estimators:
        defaultValue: 500.0
        description: Number of boosting rounds
        isOptional: true
        parameterType: NUMBER_INTEGER
      stage:
        defaultValue: staging
        description: MLflow model stage (staging/production)
        isOptional: true
        parameterType: STRING
      test_size:
        defaultValue: 0.2
        description: Fraction of data for testing
        isOptional: true
        parameterType: NUMBER_DOUBLE
  outputDefinitions:
    artifacts:
      data-loader-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
      feature-engineer-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
      register-model-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
      train-model-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
      validate-model-metrics:
        artifactType:
          schemaTitle: system.Metrics
          schemaVersion: 0.0.1
schemaVersion: 2.1.0
sdkVersion: kfp-2.7.0
